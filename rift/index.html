<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3c.org/TR/1999/REC-html401-19991224/loose.dtd">
<html xml:lang="en" xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <title>RIFT Disentangled Unsupervised Image Translation via Restricted Information Flow</title>
    <link media="all" href="https://metapose.github.io/css.css" type="text/css" rel="StyleSheet">

  </head>
  <body>
<body>
<div id="primarycontent"> 
<center><h1><b>RIFT</b>: </br> Disentangled Unsupervised Image Translation via Restricted Information Flow</h1></center>
<center><h2>
	<a href="https://usmnb.github.io/">Ben Usman*</a>&nbsp;&nbsp;&nbsp;
	<a href="https://cs-people.bu.edu/dbash/">Dina Bashkirova*</a>&nbsp;&nbsp;&nbsp;
	<a href="http://ai.bu.edu/ksaenko.html">Kate Saenko</a>
	</h2>

	<center><h2>
		Boston University
	</h2></center>
<center><h2>In WACV 2023</h2></center>
<center><h2><strong><a href="https://drive.google.com/file/d/1H6UOP31H4Ofmq06k37nQaZzn279oPxcZ/view?usp=sharing">Paper</a> | <a href="https://drive.google.com/file/d/1SjhYi87deO0ETd0_52U32cXsuL7pYhxT/view?usp=sharing"> Supplementary </a> | <a href="https://github.com/MInner/rift">Code</a> | <a href="https://www.youtube.com/watch?v=T3qTaNMjg8k"> Video </a> </strong> </h2></center>

<center style="margin-top:1cm;">
    <img src="task.png" width="500">
    </br>
    </br>
    <img src="advantages.png" width="500">
</center>
</br>
<div style="font-size:14px"><p align="justify">
MetaPose accurately estimates <b>3D human poses</b>, takes into account <b>multi-view uncertainty</b>, and uses only <b>2D supervision</b> for training!
It is <b>faster</b> and <b>more accurate</b>, especially with fewer cameras.
</p></div>

</br>
<h2 align="center">Abstract</h2>
</br>
<div style="font-size:14px"><p align="justify"> In the era of deep learning, human pose estimation from multiple cameras with unknown calibration has received little attention to date. We show how to train a neural model to perform this task with high precision and minimal latency overhead. The proposed model takes into account joint location uncertainty due to occlusion from multiple views, and requires only 2D keypoint data for training. Our method outperforms both classical bundle adjustment and weakly-supervised monocular 3D baselines on the well-established Human3.6M dataset, as well as the more challenging in-the-wild Ski-Pose PTZ dataset. </p></div>

<iframe width="560" height="315" src="https://www.youtube.com/embed/T3qTaNMjg8k" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
</br>
</br>
</br>
<h2 align="center">Citation</h2>
<pre align="left"><code align="left">
@inproceedings{usman2021metapose,
    author    = {Usman, Ben and Tagliasacchi, Andrea and Saenko, Kate and Sud, Avneesh},
    title     = {MetaPose: Fast 3D Pose from Multiple Views without 3D Supervision},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022}
}
</pre></code>
</br></br></br></br>
</body>
